{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e934d34-b519-4ceb-962d-4205a41a4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import DataHandler\n",
    "from linear_regression import LinearRegression\n",
    "# from log_regression import LogisticalRegression\n",
    "from calculations import Calculations\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ITERATIONS = 2000\n",
    "tr_log_loss = np.array(0)\n",
    "val_log_loss = np.array(0)\n",
    "\n",
    "TERMINATION_VALUE = 2**-16\n",
    "LEARNING_RATE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb73ed9-5baf-4d0b-b046-62b6180b0640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.000e-01, 2.000e-01, 1.010e+00, ..., 6.690e+02, 1.351e+03,\n",
       "         1.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 1.000e+00, 4.000e+00,\n",
       "         0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 4.000e+00, 1.500e+01,\n",
       "         0.000e+00],\n",
       "        ...,\n",
       "        [8.900e-01, 0.000e+00, 0.000e+00, ..., 9.000e+00, 7.600e+01,\n",
       "         0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 1.100e+01, 4.300e+01,\n",
       "         0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 1.500e+01, 5.000e+01,\n",
       "         0.000e+00]], dtype=float32),\n",
       " array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 1.000e+01, 9.700e+01,\n",
       "         0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 1.100e+00, ..., 7.900e+01, 3.160e+02,\n",
       "         0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 2.000e+00, 1.600e+01,\n",
       "         0.000e+00],\n",
       "        ...,\n",
       "        [4.300e-01, 4.000e-01, 3.700e-01, ..., 1.780e+02, 3.303e+03,\n",
       "         1.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 1.200e+01, 1.190e+02,\n",
       "         0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 5.000e+00, 9.000e+00,\n",
       "         0.000e+00]], dtype=float32))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator = Calculations()\n",
    "dh = DataHandler(\"spambase.data\")\n",
    "data = dh.parse_data_no_header()\n",
    "data = dh.shuffle_data(data)\n",
    "data_train, data_validation = dh.split_data(data)\n",
    "data_train, data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01fc5f61-0dac-4499-a7d3-4ed78f98ea3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3067, 57), (3067, 1), 3067, 57)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_x, training_data_y_1 = dh.getXY(\n",
    "            data_train, -1, -1)\n",
    "training_data_y = training_data_y_1.reshape((training_data_x.shape[0], -1))\n",
    "mean, std = dh.zscores(training_data_x)\n",
    "training_data_x = dh.zscore_data(mean, std, training_data_x)\n",
    "\n",
    "sample_size = training_data_x.shape[0]\n",
    "feature_size = training_data_x.shape[1]\n",
    "\n",
    "training_data_x.shape, training_data_y.shape, sample_size, feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd05a0f-9564-49a7-b23b-7c9730d2b84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1533, 57), (1533, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_x, validation_data_y = dh.getXY(\n",
    "            data_validation, -1, -1)\n",
    "validation_data_y = validation_data_y.reshape((validation_data_x.shape[0], -1))\n",
    "validation_data_x = dh.zscore_data(mean, std, validation_data_x)\n",
    "validation_data_x.shape, validation_data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ac4da4a-22ed-4f00-9a0f-468be01c0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Level: High\n",
    "def compute_log_loss(Y, p):\n",
    "    # cost = -1/m * np.sum( np.dot(np.log(A), Y.T) + np.dot(np.log(1-A), (1-Y.T)))\n",
    "    # P = P.reshape((m,-1))\n",
    "    logP = np.log(p, where=(p>0))\n",
    "    logP_min = np.log((1.0 - p), where=((1-p)>0))\n",
    "    \n",
    "    cost = -(np.dot(Y, logP)+np.dot((1-Y), logP_min))\n",
    "    return cost\n",
    "\n",
    "def prediction(w, x, b):\n",
    "    # Y_preds - Ouput size = prediction for each sample\n",
    "    # \n",
    "    P_ = sigmoid(wx_b(w, x, b))\n",
    "    Y_preds = np.zeros((1, sample_size))\n",
    "    for k in range(sample_size-1):\n",
    "        if P_[0, k] > 0.5:\n",
    "            Y_preds[0, k] = 1\n",
    "        else:\n",
    "            Y_preds[0, k] = 0\n",
    "    return Y_preds\n",
    "\n",
    "## Also interpreted as Y_hat\n",
    "def sigmoid(fxn):\n",
    "    return (1/(1+(np.exp(-fxn))))\n",
    "\n",
    "def wx_b(w, X, b):\n",
    "    return np.dot(w.T, X) + b\n",
    "\n",
    "# Confidence Level: Medium\n",
    "def compute_weights(X, b, Y, Y_):\n",
    "    diff = np.subtract(Y_, Y)\n",
    "    return (1.0/sample_size)*(np.matmul(X, diff.T))\n",
    "\n",
    "def compute_bias(Y_hat, Y):\n",
    "    m = Y.shape[0]\n",
    "    return (1.0/sample_size)*np.sum(Y_hat - Y)\n",
    "\n",
    "def train_model(w,b,X,tY, vY):\n",
    "    P = sigmoid(wx_b(w,X,b))\n",
    "    dw = compute_weights(X, b, tY, P)\n",
    "    db = compute_bias(P, tY)\n",
    "    t_cost = compute_log_loss(tY, P)\n",
    "    v_cost = compute_log_loss(tY, P)\n",
    "\n",
    "    losses = {\n",
    "        \"TR\": t_cost,\n",
    "        \"VAL\": v_cost\n",
    "    }\n",
    "    return dw, db, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cc8a8f8-fdc6-4f22-bfd8-d3850cf68b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Level: Low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f38abfab-762c-4704-b09e-00d7703b99b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,57) and (3067,57) not aligned: 57 (dim 1) != 3067 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Log Regression Calculation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ITERATIONS):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Returns in order:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m## Gradient Descent Weight\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m## Gradient Descent Bias\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m## Gradient Descent Probabilities/Y_hat\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     dw, db, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Updating the parameters.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# print(dw.shape)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# assert(dw.shape == w.shape)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m LEARNING_RATE \u001b[38;5;241m*\u001b[39m dw\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(w, b, X, tY, vY)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(w,b,X,tY, vY):\n\u001b[0;32m---> 31\u001b[0m     P \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mwx_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     32\u001b[0m     dw \u001b[38;5;241m=\u001b[39m compute_weights(X, b, tY, P)\n\u001b[1;32m     33\u001b[0m     db \u001b[38;5;241m=\u001b[39m compute_bias(P, tY)\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36mwx_b\u001b[0;34m(w, X, b)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwx_b\u001b[39m(w, X, b):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,57) and (3067,57) not aligned: 57 (dim 1) != 3067 (dim 0)"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# assert(training_data_x.shape[0] == training_data_y.shape[0])\n",
    "m, n = training_data_x.shape\n",
    "tr_costs = []\n",
    "val_costs = []\n",
    "tX = training_data_x\n",
    "tY = training_data_y\n",
    "vX = validation_data_x\n",
    "vY = validation_data_y\n",
    "w = np.zeros((sample_size,1)) # Shape -> weight for each feature of data\n",
    "b = 0\n",
    "#Log Regression Calculation\n",
    "for i in range(ITERATIONS):\n",
    "    # Returns in order:\n",
    "    ## Gradient Descent Weight\n",
    "    ## Gradient Descent Bias\n",
    "    ## Gradient Descent Probabilities/Y_hat\n",
    "    dw, db, losses = train_model(w, b, tX, tY, vY)\n",
    "\n",
    "    # Updating the parameters.\n",
    "    # print(dw.shape)\n",
    "    # assert(dw.shape == w.shape)\n",
    "    w = w - LEARNING_RATE * dw\n",
    "    b = b - LEARNING_RATE * db\n",
    "    \n",
    "    tr_costs.append(losses[\"TR\"])\n",
    "    val_costs.append(losses[\"VAL\"])\n",
    "\n",
    "    # print(\"Weight after iteration %i: \" % (i), np.array(w))\n",
    "    # print(\"Bias after iteration %i: %f\" % (i, b))\n",
    "\n",
    "    # Print costs when changed\n",
    "    if i % 100 == 0:\n",
    "        print(\"Training Mean Cost after iteration %i: %f\" % (i, np.mean(tr_costs)))\n",
    "        print(\"Validation Mean Cost after iteration %i: %f\" % (i, np.mean(val_costs)))\n",
    "        # print(\"Weight after iteration %i: \" % (i), (w))\n",
    "        # print(\"Bias after iteration %i: %f\" % (i, b))\n",
    "\n",
    "    if np.mean(val_costs) < TERMINATION_VALUE:\n",
    "        print(\"Termination Condition Hit, Exiting {}\".format(np.mean(val_costs)))\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9b113-1e1f-4df4-9d2c-af85ccd21354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(w, b)\n",
    "plt.plot(P)\n",
    "train_Y_preds = prediction(w, tX, b)\n",
    "print(train_Y_preds)\n",
    "train_acc = calculator.accuracy(tY, train_Y_preds)\n",
    "print(\"Training Accuracy {} %\".format(train_acc))\n",
    "\n",
    "val_Y_preds = prediction(w, vX, b)\n",
    "print(val_Y_preds)\n",
    "val_acc = calculator.accuracy(vY, val_Y_preds)\n",
    "print(\"Validation Accuracy {} %\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538b85c-d6c0-46f2-851f-49aafd022a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_costs = np.squeeze(tr_costs)\n",
    "val_costs = np.squeeze(val_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8a8db-8b91-4181-aa2c-38ff5012c3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(tr_costs)\n",
    "plt.title(\"Log Regression Costs\")\n",
    "\n",
    "plt.ylabel(\"cost\")\n",
    "plt.xlabel(\"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ec3a8-ec3d-4e4c-8c58-58e3a281231a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(val_costs)\n",
    "plt.title(\"Log Regression Costs\")\n",
    "\n",
    "plt.ylabel(\"cost\")\n",
    "plt.xlabel(\"iterations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
